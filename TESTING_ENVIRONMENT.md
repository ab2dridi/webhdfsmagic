# Environnement de Test HDFS pour webhdfsmagic

## üê≥ Configuration Docker

Cet environnement fournit un cluster HDFS local avec WebHDFS activ√© et un gateway (simulant Knox) pour tester webhdfsmagic.

### Composants

- **namenode**: NameNode Hadoop avec WebHDFS activ√© (port 9870)
- **datanode**: DataNode Hadoop
- **webhdfs-gateway**: Nginx agissant comme proxy (simulant Knox Gateway) (port 8080)

## üöÄ D√©marrage

```bash
# D√©marrer le cluster
docker-compose up -d

# V√©rifier que les conteneurs fonctionnent
docker ps

# Attendre ~30 secondes que HDFS s'initialise compl√®tement
```

## üîß Configuration webhdfsmagic

Le fichier de configuration est cr√©√© automatiquement dans `~/.webhdfsmagic/config.json`:

```json
{
  "knox_url": "http://localhost:8080/gateway/default",
  "webhdfs_api": "/webhdfs/v1",
  "username": "testuser",
  "password": "testpass",
  "verify_ssl": false
}
```

## ‚úÖ Tests

### Test via curl

```bash
# Lister le contenu racine
curl "http://localhost:8080/gateway/default/webhdfs/v1/?op=LISTSTATUS&user.name=testuser"

# Cr√©er un r√©pertoire
curl -X PUT "http://localhost:8080/gateway/default/webhdfs/v1/test?op=MKDIRS&user.name=testuser"

# Lister un r√©pertoire sp√©cifique
curl "http://localhost:8080/gateway/default/webhdfs/v1/test?op=LISTSTATUS&user.name=testuser"
```

### Test avec webhdfsmagic

```python
# Dans un notebook ou IPython
%load_ext webhdfsmagic

# Lister
%hdfs ls /

# Cr√©er un r√©pertoire
%hdfs mkdir /test

# Upload
%hdfs put local_file.txt /test/remote_file.txt

# Download
%hdfs get /test/remote_file.txt ./downloaded.txt
```

## üìì Utilisation du notebook de d√©monstration

The notebook `examples/demo.ipynb` contains a complete demonstration of all features with user stories.

Pour l'utiliser avec cet environnement local :

1. D√©marrez le cluster : `docker-compose up -d`
2. Ouvrez le notebook dans Jupyter
3. Ex√©cutez les cellules s√©quentiellement

Note: Certaines commandes du notebook peuvent n√©cessiter des ajustements de chemins selon votre environnement.

## üõë Arr√™t

```bash
# Arr√™ter les conteneurs
docker-compose down

# Arr√™ter et supprimer les volumes (‚ö†Ô∏è efface toutes les donn√©es HDFS)
docker-compose down -v
```

## üîç D√©bogage

### Logs des conteneurs

```bash
# Logs du namenode
docker logs namenode

# Logs du datanode  
docker logs datanode

# Logs du gateway
docker logs webhdfs-gateway
```

### Interface Web HDFS

Acc√©dez √† l'interface web du NameNode : http://localhost:9870

### Test de connectivit√©

```bash
# Test direct vers le namenode (sans gateway)
curl "http://localhost:9870/webhdfs/v1/?op=LISTSTATUS"

# Test via le gateway
curl "http://localhost:8080/gateway/default/webhdfs/v1/?op=LISTSTATUS&user.name=testuser"
```

## üìù Notes

- Cet environnement est destin√© au **d√©veloppement et aux tests uniquement**
- Les permissions HDFS sont d√©sactiv√©es (`dfs.permissions.enabled=false`) pour simplifier les tests
- Aucune authentification r√©elle n'est configur√©e (Knox est simul√© par nginx)
- Les donn√©es sont stock√©es dans des volumes Docker et persistent entre les red√©marrages

## üîê Pour tester avec SSL

Pour tester avec SSL/TLS :

1. G√©n√©rez un certificat auto-sign√©
2. D√©commentez la section HTTPS dans `nginx.conf`
3. Modifiez `config.json` :
   ```json
   {
     "knox_url": "https://localhost:8443/gateway/default",
     "webhdfs_api": "/webhdfs/v1",
     "username": "testuser",
     "password": "testpass",
     "verify_ssl": "/path/to/certificate.pem"
   }
   ```
